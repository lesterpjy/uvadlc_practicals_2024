============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Arguments:
batch_size: 64
valid_ratio: 0.75
augmentations: False
pretrained: True
num_epochs: 30
train_strats: ['standard', 'fgsm', 'pgd']
visualise: False
epsilon_fgsm: 0.1
alpha_fgsm: 0.5
epsilon_pgd: 0.01
alpha_pgd: 2
num_iter_pgd: 10
save_dir: 
test_crossover_defense: False
Device: cuda
training_strategy: standard
Loading model
/gpfs/home5/scur2818/uvadlc_practicals_2024/assignment3/part2/cifar10_models/resnet.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(script_dir + '/state_dicts/'+arch+'.pt', map_location=device)
Loading data
Files already downloaded and verified
Files already downloaded and verified
Skipping training for standard pretrained model
Testing model
Accuracy of the network on the test set: 92 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.1}
Test Accuracy = 1047 / 2500 = 0.4188
Attack pgd, args: {'alpha': 2, 'epsilon': 0.01, 'num_iter': 10}
Test Accuracy = 1106 / 2500 = 0.4424
training_strategy: fgsm
Loading model
Loading data
Files already downloaded and verified
Files already downloaded and verified
Training model
Epoch 0/29
----------
train Loss: 0.6021 Acc: 0.9844
val Loss: 0.3493 Acc: 0.8819
Epoch 1/29
----------
train Loss: 0.4440 Acc: 0.9909
val Loss: 0.3425 Acc: 0.8886
Epoch 2/29
----------
train Loss: 0.3601 Acc: 0.9938
val Loss: 0.3706 Acc: 0.8812
Epoch 3/29
----------
train Loss: 0.3013 Acc: 0.9946
val Loss: 0.3714 Acc: 0.8814
Epoch 4/29
----------
train Loss: 0.2518 Acc: 0.9957
val Loss: 0.4038 Acc: 0.8806
Epoch 5/29
----------
train Loss: 0.2079 Acc: 0.9964
val Loss: 0.4195 Acc: 0.8791
Epoch 6/29
----------
train Loss: 0.1750 Acc: 0.9969
val Loss: 0.4335 Acc: 0.8766
Epoch 7/29
----------
train Loss: 0.1156 Acc: 0.9983
val Loss: 0.4189 Acc: 0.8803
Epoch 8/29
----------
train Loss: 0.0974 Acc: 0.9985
val Loss: 0.4490 Acc: 0.8776
Epoch 9/29
----------
train Loss: 0.0859 Acc: 0.9986
val Loss: 0.4378 Acc: 0.8784
Epoch 10/29
----------
train Loss: 0.0794 Acc: 0.9987
val Loss: 0.4469 Acc: 0.8796
Epoch 11/29
----------
train Loss: 0.0728 Acc: 0.9986
val Loss: 0.4646 Acc: 0.8753
Epoch 12/29
----------
train Loss: 0.0683 Acc: 0.9987
val Loss: 0.4663 Acc: 0.8746
Epoch 13/29
----------
train Loss: 0.0636 Acc: 0.9987
val Loss: 0.4557 Acc: 0.8778
Epoch 14/29
----------
train Loss: 0.0585 Acc: 0.9987
val Loss: 0.4772 Acc: 0.8717
Epoch 15/29
----------
train Loss: 0.0572 Acc: 0.9988
val Loss: 0.4812 Acc: 0.8724
Epoch 16/29
----------
train Loss: 0.0569 Acc: 0.9987
val Loss: 0.4777 Acc: 0.8724
Epoch 17/29
----------
train Loss: 0.0564 Acc: 0.9987
val Loss: 0.4935 Acc: 0.8714
Epoch 18/29
----------
train Loss: 0.0561 Acc: 0.9987
val Loss: 0.4673 Acc: 0.8754
Epoch 19/29
----------
train Loss: 0.0546 Acc: 0.9987
val Loss: 0.4925 Acc: 0.8727
Epoch 20/29
----------
train Loss: 0.0552 Acc: 0.9988
val Loss: 0.4703 Acc: 0.8753
Epoch 21/29
----------
train Loss: 0.0542 Acc: 0.9988
val Loss: 0.4696 Acc: 0.8762
Epoch 22/29
----------
train Loss: 0.0545 Acc: 0.9987
val Loss: 0.4911 Acc: 0.8724
Epoch 23/29
----------
train Loss: 0.0562 Acc: 0.9988
val Loss: 0.4738 Acc: 0.8745
Epoch 24/29
----------
train Loss: 0.0550 Acc: 0.9988
val Loss: 0.4809 Acc: 0.8733
Epoch 25/29
----------
train Loss: 0.0535 Acc: 0.9988
val Loss: 0.4881 Acc: 0.8692
Epoch 26/29
----------
train Loss: 0.0535 Acc: 0.9986
val Loss: 0.4713 Acc: 0.8734
Epoch 27/29
----------
train Loss: 0.0545 Acc: 0.9987
val Loss: 0.4756 Acc: 0.8731
Epoch 28/29
----------
train Loss: 0.0535 Acc: 0.9988
val Loss: 0.4818 Acc: 0.8722
Epoch 29/29
----------
train Loss: 0.0543 Acc: 0.9988
val Loss: 0.4921 Acc: 0.8712
Training complete in 7m 45s
Best val Acc: 0.888639
Testing model
Accuracy of the network on the test set: 90 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.1}
Test Accuracy = 1470 / 2500 = 0.588
training_strategy: pgd
Loading model
Loading data
Files already downloaded and verified
Files already downloaded and verified
Training model
Epoch 0/29
----------
train Loss: 0.0068 Acc: 0.4978
val Loss: 0.6716 Acc: 0.8502
Epoch 1/29
----------
train Loss: 0.0054 Acc: 0.4984
val Loss: 0.6848 Acc: 0.8424
Epoch 2/29
----------
train Loss: 0.0055 Acc: 0.4981
val Loss: 0.6810 Acc: 0.8551
Epoch 3/29
----------
train Loss: 0.0039 Acc: 0.4987
val Loss: 0.7131 Acc: 0.8350
Epoch 4/29
----------
train Loss: 0.0042 Acc: 0.4985
val Loss: 0.8274 Acc: 0.8263
Epoch 5/29
----------
train Loss: 0.0029 Acc: 0.4990
val Loss: 0.7199 Acc: 0.8475
Epoch 6/29
----------
train Loss: 0.0027 Acc: 0.4990
val Loss: 0.7176 Acc: 0.8538
Epoch 7/29
----------
train Loss: 0.0021 Acc: 0.4992
val Loss: 0.6260 Acc: 0.8686
Epoch 8/29
----------
train Loss: 0.0016 Acc: 0.4994
val Loss: 0.6335 Acc: 0.8648
Epoch 9/29
----------
train Loss: 0.0017 Acc: 0.4993
val Loss: 0.6096 Acc: 0.8665
Epoch 10/29
----------
train Loss: 0.0014 Acc: 0.4994
val Loss: 0.5740 Acc: 0.8739
Epoch 11/29
----------
train Loss: 0.0013 Acc: 0.4995
val Loss: 0.8345 Acc: 0.8312
Epoch 12/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.5594 Acc: 0.8755
Epoch 13/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.8904 Acc: 0.8208
Epoch 14/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.6280 Acc: 0.8594
Epoch 15/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.6698 Acc: 0.8563
Epoch 16/29
----------
train Loss: 0.0014 Acc: 0.4994
val Loss: 0.7099 Acc: 0.8517
Epoch 17/29
----------
train Loss: 0.0013 Acc: 0.4995
val Loss: 0.6651 Acc: 0.8573
Epoch 18/29
----------
train Loss: 0.0012 Acc: 0.4995
val Loss: 0.6677 Acc: 0.8554
Epoch 19/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.6829 Acc: 0.8586
Epoch 20/29
----------
train Loss: 0.0012 Acc: 0.4995
val Loss: 0.6117 Acc: 0.8724
Epoch 21/29
----------
train Loss: 0.0012 Acc: 0.4994
val Loss: 0.6373 Acc: 0.8659
Epoch 22/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.7238 Acc: 0.8428
Epoch 23/29
----------
train Loss: 0.0012 Acc: 0.4994
val Loss: 0.6347 Acc: 0.8665
Epoch 24/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.7764 Acc: 0.8424
Epoch 25/29
----------
train Loss: 0.0012 Acc: 0.4995
val Loss: 0.6893 Acc: 0.8551
Epoch 26/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.7384 Acc: 0.8459
Epoch 27/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.7009 Acc: 0.8532
Epoch 28/29
----------
train Loss: 0.0013 Acc: 0.4994
val Loss: 0.6636 Acc: 0.8640
Epoch 29/29
----------
train Loss: 0.0012 Acc: 0.4994
val Loss: 0.6681 Acc: 0.8614
Training complete in 30m 57s
Best val Acc: 0.875530
Testing model
Accuracy of the network on the test set: 88 %
Testing adversarial attacks
Attack pgd, args: {'alpha': 2, 'epsilon': 0.01, 'num_iter': 10}
Test Accuracy = 1258 / 2500 = 0.5032

JOB STATISTICS
==============
Job ID: 8952957
Cluster: snellius
User/Group: scur2818/scur2818
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:58:57
CPU Efficiency: 7.31% of 13:26:24 core-walltime
Job Wall-clock time: 00:44:48
Memory Utilized: 1006.54 MB
Memory Efficiency: 3.15% of 31.25 GB
