============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Arguments:
batch_size: 64
valid_ratio: 0.75
augmentations: True
pretrained: True
num_epochs: 30
train_strats: ['standard', 'fgsm', 'pgd']
visualise: False
epsilon_fgsm: 0.1
alpha_fgsm: 0.5
epsilon_pgd: 0.01
alpha_pgd: 2
num_iter_pgd: 10
save_dir: 
test_crossover_defense: True
Device: cuda
training_strategy: standard
Loading model
/gpfs/home5/scur2818/uvadlc_practicals_2024/assignment3/part2/cifar10_models/resnet.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(script_dir + '/state_dicts/'+arch+'.pt', map_location=device)
Loading data
Files already downloaded and verified
Files already downloaded and verified
Skipping training for standard pretrained model
Testing model
Accuracy of the network on the test set: 92 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.1}
Test Accuracy = 1039 / 2500 = 0.4156
Attack pgd, args: {'alpha': 2, 'epsilon': 0.01, 'num_iter': 10}
Test Accuracy = 1080 / 2500 = 0.432
training_strategy: fgsm
Loading model
Loading data
Files already downloaded and verified
Files already downloaded and verified
Training model
Epoch 0/29
----------
train Loss: 0.6105 Acc: 0.9830
val Loss: 0.3608 Acc: 0.8790
Epoch 1/29
----------
train Loss: 0.4863 Acc: 0.9861
val Loss: 0.3602 Acc: 0.8753
Epoch 2/29
----------
train Loss: 0.4313 Acc: 0.9880
val Loss: 0.3744 Acc: 0.8734
Epoch 3/29
----------
train Loss: 0.3996 Acc: 0.9890
val Loss: 0.3743 Acc: 0.8733
Epoch 4/29
----------
train Loss: 0.3781 Acc: 0.9898
val Loss: 0.3879 Acc: 0.8702
Epoch 5/29
----------
train Loss: 0.3657 Acc: 0.9895
val Loss: 0.3523 Acc: 0.8811
Epoch 6/29
----------
train Loss: 0.3460 Acc: 0.9901
val Loss: 0.3731 Acc: 0.8743
Epoch 7/29
----------
train Loss: 0.3168 Acc: 0.9928
val Loss: 0.3754 Acc: 0.8791
Epoch 8/29
----------
train Loss: 0.3082 Acc: 0.9935
val Loss: 0.3737 Acc: 0.8784
Epoch 9/29
----------
train Loss: 0.3028 Acc: 0.9937
val Loss: 0.3621 Acc: 0.8814
Epoch 10/29
----------
train Loss: 0.3001 Acc: 0.9944
val Loss: 0.3683 Acc: 0.8822
Epoch 11/29
----------
train Loss: 0.2984 Acc: 0.9943
val Loss: 0.3616 Acc: 0.8824
Epoch 12/29
----------
train Loss: 0.2958 Acc: 0.9948
val Loss: 0.3816 Acc: 0.8796
Epoch 13/29
----------
train Loss: 0.2947 Acc: 0.9950
val Loss: 0.3991 Acc: 0.8721
Epoch 14/29
----------
train Loss: 0.2889 Acc: 0.9942
val Loss: 0.3787 Acc: 0.8773
Epoch 15/29
----------
train Loss: 0.2883 Acc: 0.9948
val Loss: 0.3776 Acc: 0.8778
Epoch 16/29
----------
train Loss: 0.2904 Acc: 0.9949
val Loss: 0.3785 Acc: 0.8792
Epoch 17/29
----------
train Loss: 0.2874 Acc: 0.9948
val Loss: 0.3881 Acc: 0.8775
Epoch 18/29
----------
train Loss: 0.2880 Acc: 0.9947
val Loss: 0.3892 Acc: 0.8742
Epoch 19/29
----------
train Loss: 0.2863 Acc: 0.9946
val Loss: 0.3790 Acc: 0.8791
Epoch 20/29
----------
train Loss: 0.2874 Acc: 0.9945
val Loss: 0.3879 Acc: 0.8774
Epoch 21/29
----------
train Loss: 0.2889 Acc: 0.9949
val Loss: 0.3930 Acc: 0.8737
Epoch 22/29
----------
train Loss: 0.2858 Acc: 0.9948
val Loss: 0.3820 Acc: 0.8769
Epoch 23/29
----------
train Loss: 0.2883 Acc: 0.9949
val Loss: 0.3707 Acc: 0.8825
Epoch 24/29
----------
train Loss: 0.2866 Acc: 0.9953
val Loss: 0.3643 Acc: 0.8820
Epoch 25/29
----------
train Loss: 0.2875 Acc: 0.9952
val Loss: 0.4082 Acc: 0.8712
Epoch 26/29
----------
train Loss: 0.2860 Acc: 0.9952
val Loss: 0.3774 Acc: 0.8811
Epoch 27/29
----------
train Loss: 0.2872 Acc: 0.9948
val Loss: 0.4171 Acc: 0.8734
Epoch 28/29
----------
train Loss: 0.2865 Acc: 0.9947
val Loss: 0.3862 Acc: 0.8773
Epoch 29/29
----------
train Loss: 0.2850 Acc: 0.9950
val Loss: 0.3919 Acc: 0.8743
Training complete in 7m 43s
Best val Acc: 0.882548
Testing model
Accuracy of the network on the test set: 89 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.1}
Test Accuracy = 1397 / 2500 = 0.5588
Attack pgd, args: {'alpha': 2, 'epsilon': 0.01, 'num_iter': 10}
Test Accuracy = 1525 / 2500 = 0.61
training_strategy: pgd
Loading model
Loading data
Files already downloaded and verified
Files already downloaded and verified
Training model
Epoch 0/29
----------
train Loss: 0.0066 Acc: 0.4978
val Loss: 1.1449 Acc: 0.7456
Epoch 1/29
----------
train Loss: 0.0106 Acc: 0.4966
val Loss: 1.2038 Acc: 0.7378
Epoch 2/29
----------
train Loss: 0.0111 Acc: 0.4963
val Loss: 1.2514 Acc: 0.7431
Epoch 3/29
----------
train Loss: 0.0134 Acc: 0.4956
val Loss: 0.9867 Acc: 0.7676
Epoch 4/29
----------
train Loss: 0.0117 Acc: 0.4959
val Loss: 1.4274 Acc: 0.7083
Epoch 5/29
----------
train Loss: 0.0130 Acc: 0.4956
val Loss: 0.9010 Acc: 0.7925
Epoch 6/29
----------
train Loss: 0.0132 Acc: 0.4957
val Loss: 0.9344 Acc: 0.7884
Epoch 7/29
----------
train Loss: 0.0079 Acc: 0.4975
val Loss: 0.9461 Acc: 0.7798
Epoch 8/29
----------
train Loss: 0.0058 Acc: 0.4981
val Loss: 1.1470 Acc: 0.7526
Epoch 9/29
----------
train Loss: 0.0049 Acc: 0.4984
val Loss: 1.0197 Acc: 0.7756
Epoch 10/29
----------
train Loss: 0.0044 Acc: 0.4986
val Loss: 1.1277 Acc: 0.7650
Epoch 11/29
----------
train Loss: 0.0047 Acc: 0.4983
val Loss: 1.0450 Acc: 0.7818
Epoch 12/29
----------
train Loss: 0.0043 Acc: 0.4985
val Loss: 0.9001 Acc: 0.7933
Epoch 13/29
----------
train Loss: 0.0037 Acc: 0.4988
val Loss: 1.1560 Acc: 0.7626
Epoch 14/29
----------
train Loss: 0.0037 Acc: 0.4989
val Loss: 0.9885 Acc: 0.7738
Epoch 15/29
----------
train Loss: 0.0037 Acc: 0.4987
val Loss: 0.7876 Acc: 0.8109
Epoch 16/29
----------
train Loss: 0.0035 Acc: 0.4989
val Loss: 0.8213 Acc: 0.7999
Epoch 17/29
----------
train Loss: 0.0034 Acc: 0.4989
val Loss: 1.0505 Acc: 0.7765
Epoch 18/29
----------
train Loss: 0.0034 Acc: 0.4988
val Loss: 1.0913 Acc: 0.7680
Epoch 19/29
----------
train Loss: 0.0034 Acc: 0.4989
val Loss: 0.8332 Acc: 0.8158
Epoch 20/29
----------
train Loss: 0.0034 Acc: 0.4989
val Loss: 0.9474 Acc: 0.7872
Epoch 21/29
----------
train Loss: 0.0034 Acc: 0.4989
val Loss: 0.9831 Acc: 0.7922
Epoch 22/29
----------
train Loss: 0.0030 Acc: 0.4990
val Loss: 0.8188 Acc: 0.8050
Epoch 23/29
----------
train Loss: 0.0032 Acc: 0.4989
val Loss: 1.0768 Acc: 0.7692
Epoch 24/29
----------
train Loss: 0.0033 Acc: 0.4989
val Loss: 0.8190 Acc: 0.8136
Epoch 25/29
----------
train Loss: 0.0035 Acc: 0.4989
val Loss: 0.8990 Acc: 0.8022
Epoch 26/29
----------
train Loss: 0.0032 Acc: 0.4988
val Loss: 0.9868 Acc: 0.7933
Epoch 27/29
----------
train Loss: 0.0032 Acc: 0.4990
val Loss: 0.7962 Acc: 0.8162
Epoch 28/29
----------
train Loss: 0.0035 Acc: 0.4988
val Loss: 0.8618 Acc: 0.7989
Epoch 29/29
----------
train Loss: 0.0034 Acc: 0.4989
val Loss: 0.8087 Acc: 0.8109
Training complete in 30m 43s
Best val Acc: 0.816208
Testing model
Accuracy of the network on the test set: 82 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.1}
Test Accuracy = 1110 / 2500 = 0.444
Attack pgd, args: {'alpha': 2, 'epsilon': 0.01, 'num_iter': 10}
Test Accuracy = 1211 / 2500 = 0.4844

JOB STATISTICS
==============
Job ID: 8953821
Cluster: snellius
User/Group: scur2818/scur2818
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:06:06
CPU Efficiency: 7.83% of 14:04:30 core-walltime
Job Wall-clock time: 00:46:55
Memory Utilized: 1.06 GB
Memory Efficiency: 3.39% of 31.25 GB
