#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=GPT_generate
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=04:00:00
#SBATCH --output=gpt_generate_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2

# Your job starts in the directory where you call sbatch
cd $HOME/uvadlc_practicals_2024/assignment2/part2/
# Activate your environment
source activate dl2024

# Define the list of prompts and their parameters
prompt_list=(
    "Once upon a time, in a faraway kingdom, there lived a humble woodcutter and his wife, who had two children named |0.7|0.9"
    "The king proclaimed, "Whoever can spin straw into gold shall |0.65|0.9"
    "As soon as she was alone that dwarf came in, and said, â€˜What will you give me to spin |1.0|0.9"
    "'Grandmother, what big eyes you have!' exclaimed Little Red Riding Hood. 'All the better to |0.6|0.9"
    "The dark forest was filled with ancient trees whose twisted branches reached out like |0.75|0.95"
    "The talking fox approached the lost traveler and offered to guide him in exchange for |0.7|0.9"
    "'Harken to my words,' the old sage declared, "for the path ahead is fraught with |0.7|0.9"
    "In the first chapter, the youngest brother received an enchanted cloak. Now, as he faced the dragon, he remembered |0.65|0.85"
)

# Loop through the prompts
for prompt_info in "${prompt_list[@]}"; do
    # Split the prompt_info into components
    IFS='|' read -r prompt temperature top_p <<< "$prompt_info"
    
    # Print the details to the output
    printf "Running with prompt: '%s', temperature: %s, top_p: %s\n" "$prompt" "$temperature" "$top_p"

    # Run generate.py with the current prompt and parameters
    srun python generate.py --num_samples 5 --temperature "$temperature" --top_p "$top_p" --prompt "$prompt"
done
